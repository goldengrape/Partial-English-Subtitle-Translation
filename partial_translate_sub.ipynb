{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysubs2\n",
    "import re\n",
    "from stardict import DictCsv\n",
    "# from stardict import LemmaDB\n",
    "from googletrans import Translator\n",
    "import pandas\n",
    "from difflib import SequenceMatcher \n",
    "import itertools\n",
    "import string\n",
    "\n",
    "# depend on https://github.com/skywind3000/ECDICT/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tranlate(source):\n",
    "\n",
    "    import requests\n",
    "    import json\n",
    "    \n",
    "    url = \"http://api.interpreter.caiyunai.com/v1/translator\"\n",
    "    \n",
    "    #WARNING, this token is a test token for new developers, and it should be replaced by your token\n",
    "    token = \"3975l6lr5pcbvidl6jl2\"\n",
    "    \n",
    "    \n",
    "    payload = {\n",
    "            \"source\" : source, \n",
    "            \"trans_type\" : \"en2zh\",\n",
    "            \"request_id\" : \"demo\",\n",
    "            \"detect\": True,\n",
    "            }\n",
    "    \n",
    "    headers = {\n",
    "            'content-type': \"application/json\",\n",
    "            'x-authorization': \"token \" + token,\n",
    "    }\n",
    "    \n",
    "    response = requests.request(\"POST\", url, data=json.dumps(payload), headers=headers)\n",
    "\n",
    "    return json.loads(response.text)['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longestSubstring(str1,str2): \n",
    "     # 两个字符串最长公共字符串\n",
    "     # initialize SequenceMatcher object with  \n",
    "     # input string \n",
    "    seqMatch = SequenceMatcher(None,str1,str2) \n",
    "  \n",
    "     # find match of longest sub-string \n",
    "     # output will be like Match(a=0, b=0, size=5) \n",
    "    match = seqMatch.find_longest_match(0, len(str1), 0, len(str2)) \n",
    "  \n",
    "     # print longest substring \n",
    "    if (match.size!=0): \n",
    "          return (str1[match.a: match.a + match.size])  \n",
    "    else: \n",
    "          return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trans(word_trans_from_dict, word_trans_from_translator, sentence_trans):\n",
    "    # 句子中的单词含义, 如果没有公共的, 就返回查到的词\n",
    "    match=longestSubstring(sentence_trans,word_trans_from_dict)\n",
    "    if match==\"\":\n",
    "        return word_trans_from_translator.replace(r\"\\n\", \"\").translate(str.maketrans('', '', string.punctuation))\n",
    "    else:\n",
    "        return match.replace(r\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_unknown(word_query):\n",
    "    if not(word_query):\n",
    "        return False\n",
    "    # 是否认识?\n",
    "    tag_check={'cet4':False, 'cet6':False, 'toelf':True ,\"gre\":True,'ielts':True}\n",
    "    collins_threshold=2; collins_default=True\n",
    "    bnc_threshold=5000; bnc_default=True\n",
    "    frq_threshold=5000; frq_default=True\n",
    "    \n",
    "    # check tag\n",
    "    chk1=True\n",
    "    chk2=True\n",
    "    for (key, value) in tag_check.items():\n",
    "        if not(value):\n",
    "            chk1 = chk1 and not((key in word_query['tag']) if word_query['tag'] else True) \n",
    "        else: \n",
    "            chk2 = chk2 or ((key in word_query['tag']) if word_query['tag'] else True)\n",
    "    tag_chk = chk1 and chk2\n",
    "    \n",
    "    # check collins\n",
    "    collins_chk = (word_query['collins']<=collins_threshold) if word_query['collins']>=0 else collins_default\n",
    "    \n",
    "    # check bnc\n",
    "    bnc_chk=(word_query['bnc']>=bnc_threshold) if word_query['bnc']>0 else bnc_default\n",
    "    \n",
    "    # check frq\n",
    "    frq_chk=(word_query['frq']>=frq_threshold) if word_query['bnc']>0 else frq_default\n",
    "\n",
    "    return (tag_chk+collins_chk+bnc_chk+frq_chk) >=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trans_to_sentence(s, sdict, translator):\n",
    "    sentence=s.replace(\"\\\\N\", \" \").replace(\"\\n\", \" \").translate(str.maketrans('', '', string.punctuation))\n",
    "    words=sentence.split()\n",
    "    words_to_trans={}\n",
    "    for word in words:\n",
    "        word_query=sdict.query(word) if sdict.query(word) else sdict.query('unknown')   \n",
    "        if word_unknown(word_query):\n",
    "            words_to_trans[word]=word_query['translation']\n",
    "    to_trans_list=[[sentence], words_to_trans.keys()]\n",
    "    to_trans_list=list(itertools.chain(*to_trans_list))\n",
    "    trans=tranlate(to_trans_list)\n",
    "    sentence_trans=trans[0]\n",
    "    word_with_trans={}\n",
    "    for idx, word in enumerate(words_to_trans.keys()):\n",
    "        word_trans=trans[idx+1]\n",
    "        word_with_trans[word]=get_trans(words_to_trans[word], word_trans, sentence_trans)\n",
    "    for (word, meaning) in word_with_trans.items():\n",
    "        meaning=word+\"(\"+meaning+\")\"\n",
    "        s=s[0:s.find(word)]+meaning+s[(s.find(word)+len(word)):]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_filename=\"ecdict.csv\"\n",
    "lemma_filename='lemma.en.txt'\n",
    "sub_filename=\"01sub.srt\"\n",
    "subs = pysubs2.load(sub_filename, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdict=DictCsv(dict_filename)\n",
    "# lemma = LemmaDB()\n",
    "# lemma.load(lemma_filename)\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have arrived(到达)\\Nat the dawn of a new era.\n",
      "We will face the unknown\\Ntogether.\n",
      "I don't know what it is,\n",
      "but there's plenty of people\\Nout hertheres(有)here's plenty of people\\Nout here\n",
      "trying(尝试) to figure it out.\n",
      "You know I've got your backIve(伊夫)u know I've got your back.\n",
      "Damn well better,\\NI'm your captain.\n",
      "We have to work together.\n",
      "For the good of\\Nthe new Belter(了) state.\n",
      "Detective Miller\\Ncrashed(崩溃) into Venus.\n",
      "I'm just an investigator now.\n",
      "I find things(事情).\n",
      "Couple hundred billion\\Nbrain cells(细胞) in your skull.\n",
      "When I push a few trillion(万亿)\\Nof them buttons(按钮)\n",
      "in exactly the right way,\\Nyou're talking(说话) to Miller.\n",
      "Miller showed(显示) me things(事情).\n",
      "A whole civilization.\n",
      "They made(成) the station,\\Nthis space.\n",
      "Something killed them.\\NThey tried(试) to stop it.\n",
      "Burned(烧焦了) whole solar systems(系).\n",
      "Only, it didn't work.\n",
      "When we detonated(引爆) our bomb,\n",
      "I believe\\Nwe became(成为) the threat.\n",
      "We taught(教) the station\n",
      "that our ships(的)\\Nare(的) fusion(聚变) bombs(炸弹).\n",
      "We need to shut down every\\Nreactor in the flotilla(船队).\n",
      "That station is gonna(要)\\Nwipe us all out,\n",
      "unless we make this\\Nhappen now.\n",
      "Together till the end?\n",
      "We're on the brink(边缘) right noWere(的)re on the brink right now\n",
      "because we keep reacting(反应) to\\Nthings(情) we don't understand!\n",
      "And we're reaching(在)\\Nfor violencwere(曾经) we're reaching\\Nfor violence\n",
      "because we can't figure out\\Nwhat to docant(斜面)ause we can't figure out\\Nwhat to do.\n",
      "Don't shoot!\n",
      "Fuck(操).\n",
      "You've given us\\Na new frontier,\n",
      "1,300 habitable(可居住) systems(系统) on\\Nthe other side of those rings(环).\n",
      "It's gonna(将) be another\\Nblood-soaked gold rush.\n",
      "The civilization that built(的)\\Nthe rings(环) is gone, wiped(的) out.\n",
      "What could have killed them?\n",
      "That's what\\NI'd like to know.\n",
      "Gonna(要) need a ride.\n",
      "Unidentified\\NBelter(不) ships(的),\n",
      "you are(在) entering(进入)\\Nrestricted(限制) space.\n",
      "Veer(转向) off now, or we will fire!\n",
      "Barbapiccola,\\Nthis is the UNN( ) Tripoli.\n",
      "Shut down your drive now,\\Nor we will fire.\n",
      "Respond immediately.\n",
      "We are(是) unarmed(没有武).\\NThis is a refugee ship.\n",
      "Mama(妈妈), I'm scared.\n",
      "Whatever happens(发生),\\Nwe will be together.\n",
      "Together.\n",
      "Tripoli,\\Nyou are(的) not authorized(授权)\n",
      "to fire inside the Ring Space.\n",
      "Barbapiccola, the OPA(蛋白酶 a)\\Norders(命令) you to comply.\n",
      "We will not.\n",
      "We've been(一直) begging(乞求)\\Nfor a port\n",
      "since Ganymede(Ganymede) fell( ).\n",
      "No one would let us land.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-75555d9f7fbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_trans_to_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b5cbb09f5c68>\u001b[0m in \u001b[0;36madd_trans_to_sentence\u001b[0;34m(s, sdict, translator)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mto_trans_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_to_trans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mto_trans_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mto_trans_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranlate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_trans_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0msentence_trans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mword_with_trans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-95d6fa99a495>\u001b[0m in \u001b[0;36mtranlate\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'target'"
     ]
    }
   ],
   "source": [
    "for line in subs:\n",
    "    s=line.text\n",
    "    line.text=add_trans_to_sentence(s, sdict, translator)\n",
    "    print(line.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs.save(\"my_subtitles_edited.srt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
